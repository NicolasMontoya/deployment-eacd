# EACD 2021 - MLOps - FastAPI Python / FaunaDB

Ejemplo de despliegue de modelo de machine learning. El objetivo de este proyecto es desplegar un servicio web capaz de predecir la cantidad de bicicletas requeridas en un sistema de bicicletas públicas. A continuación encontramos la descripción tomada de la fuente original.

```
Background

Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return back at another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues.

Apart from interesting real world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for the research. Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems. This feature turns bike sharing system into a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that most of important events in the city could be detected via monitoring these data.

Data Set

Bike-sharing rental process is highly correlated to the environmental and seasonal settings. For instance, weather conditions, precipitation, day of week, season, hour of the day, etc. can affect the rental behaviors. The core data set is related to
the two-year historical log corresponding to years 2011 and 2012 from Capital Bikeshare system, Washington D.C., USA which is publicly available in http://capitalbikeshare.com/system-data. We aggregated the data on two hourly and daily basis and then extracted and added the corresponding weather and seasonal information. Weather information are extracted from http://www.freemeteo.com.

Dataset characteristics
data.csv has the following fields:

- instant: record index
- dteday : date
- season : season (1:springer, 2:summer, 3:fall, 4:winter)
- yr : year (0: 2011, 1:2012)
- mnth : month ( 1 to 12)
- hr : hour (0 to 23)
- holiday : weather day is holiday or not (extracted from http://dchr.dc.gov/page/holiday-schedule)
- weekday : day of the week
- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.
+ weathersit : 
	- 1: Clear, Few clouds, Partly cloudy, Partly cloudy
	- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist
	- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds
	- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog
- temp : Normalized temperature in Celsius. The values are divided to 41 (max)
- atemp: Normalized feeling temperature in Celsius. The values are divided to 50 (max)
- hum: Normalized humidity. The values are divided to 100 (max)
- windspeed: Normalized wind speed. The values are divided to 67 (max)
- casual: count of casual users
- registered: count of registered users
- cnt: count of total rental bikes including both casual and registered
```

Organización de proyecto
------------

    │
    ├── app                         <- Carpeta que contiene la estructura de FastAPI
    |   |
    │   ├── __init__.py             <- Definición de modulo de Python
    │   │
    │   ├── datasets                <- Almacena los dataset de entrenamiento
    |   |       
    |   |── models                  <- Almacenamiento y configuración de modelos (Persistencia y presentación)
    |   |       |
    |   |       |── ml              <- Almacena los modelos de ML generados por SKLearn
    |   |       |
    |   |       |── __init__.py     <- Definición de modulo de Python
    |   |       |
    |   |       |── database.py     <- Archivo de configuración de la base de datos
    |   |       |
    |   |       |── schema.py       <- Definición de DTO para control de la capa de presentación
    │   │
    |   |── routers                 <- Routers de acceso a la aplicación
    |   |       |
    |   |       |── __init__.py     <- Definición de modulo de Python
    |   |       |
    |   |       |── datasets.py     <- Routers de acceso a /datasets
    |   |       |
    |   |       |── models.py       <- Routers de acceso a /models
    │   │
    |   |── services                <- Servicios
    |   |       |
    |   |       |── __init__.py     <- Definición de modulo de Python
    |   |       |
    |   |       |── helpers.py      <- Clases de soporte para el entramiento de los modelos
    |   |       |
    |   |       |── model_service.py  <- Clases y funciones enfocadas en ML
    │   │    
    │   └── main.py                 <- Punto de anclaje de la aplicación web
    │
    ├── docs                        <- Carpeta con documentación relacionada con el proyecto
    │
    ├── notebooks                   <- Jupyter notebooks. Contiene los notebooks usados para diseñar el
    │                                   servicio de machine learning
    |
    ├── tests                       <- Directorio de configuración para pruebas
    |
    │── .env                        <- Archivo de configuración de variables (NO SE SUBE A REPOSITORIOS
    |                                 PÚBLICOS)
    |
    │── .gitignore                  <- Define los archivos a ignorar por git
    │
    │── DockerFile                  <- Archivo de configuración para despliegue mediante docker
    |
    ├── README.md                   <- Archivo guía para la configutación del proyecto
    |
    └─ requirements.txt             <- Instala las dependencias asociadas al proyecto mediante PyPi


--------

## Elementos requeridos para el despliegue

- Docker
- Cuenta gratuita de FaunaDB

## Configuración de FaunaDB

- Crear cuenta gratuita en FaunaDB https://fauna.com/

- Crear base de datos

![](https://firebasestorage.googleapis.com/v0/b/test-29537.appspot.com/o/Screenshot%202021-03-18%20232921.jpg?alt=media&token=254ffa69-3b63-4c6e-a27c-a9daacab21e5)

- Dentro de la base de datos ir a la pestaña seguridad y crear una nueva clave de acceso.

![](https://firebasestorage.googleapis.com/v0/b/test-29537.appspot.com/o/Screenshot%202021-03-18%20233204.jpg?alt=media&token=1591372e-3e41-488e-977b-21feb102752a)

- Seleccionar la base de datos creada y el rol de admin.

![](https://firebasestorage.googleapis.com/v0/b/test-29537.appspot.com/o/Screenshot%202021-03-18%20233343.jpg?alt=media&token=1805f443-3e79-491d-9443-97779d979793)

- Copiar la clave de acceso segura generada por FaunaDB (Esta clave es única y no puede consultarse en el futuro).

![](https://firebasestorage.googleapis.com/v0/b/test-29537.appspot.com/o/Screenshot%202021-03-18%20233741.jpg?alt=media&token=59991571-c5b5-4d74-87ca-c73d5e0370aa)

- Crear las siguientes collecciones: datasets, predictions y models.

![](https://firebasestorage.googleapis.com/v0/b/test-29537.appspot.com/o/Screenshot%202021-03-18%20233936.jpg?alt=media&token=f9f60c28-b5d7-489a-8208-0d32d176ac30)

## Despliegue de la aplicación

1. Crear en la raiz del proyecto el archivo .env con la siguiente linea FAUNA_SECRET=`SECRET_KEY` donde SECRET_KEY 
es la clave entregada por fauna.
2. Parados en la raíz ejecutar `docker image build -t api-ml .`
3. Correr el contenedor `docker run --env-file .env --publish 80:80 api-ml`